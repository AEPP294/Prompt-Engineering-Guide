# Automatic Prompt Engineer (APE)

import { Callout, FileTree } from 'nextra-theme-docs'
import {Screenshot} from 'components/screenshot'
import APE from '../../img/APE.png'
import APECOT from '../../img/ape-zero-shot-cot.png'

<Screenshot src={APE} alt="APE" />
Fuente de la imagen:  [Zhou et al., (2022)](https://arxiv.org/abs/2211.01910)

[Zhou et al., (2022)](https://arxiv.org/abs/2211.01910) proponer al ingeniero automático de avisos (APE) un marco para la generación y selección automática de instrucciones. El problema de generación de instrucciones se enmarca como síntesis de lenguaje natural abordado como un problema de optimización de caja negra utilizando LLM para generar y buscar soluciones candidatas. 

El primer paso implica un modelo de lenguaje grande (como un modelo de inferencia) que se da demostraciones de salida para generar candidatos de instrucción para una tarea. Estas soluciones candidatas guiarán el procedimiento de búsqueda. Las instrucciones se ejecutan utilizando un modelo de destino y, a continuación, se selecciona la instrucción más adecuada en función de las puntuaciones de evaluación calculadas.

APE descubre un indicador de CoT de disparo cero mejor que el indicador "Pensemos paso a paso" diseñado por humanos ([Kojima et al., 2022](https://arxiv.org/abs/2205.11916)).

El prompt "Vamos a resolver esto paso a paso para asegurarnos de que tenemos la respuesta correcta" provoca un razonamiento de cadena de pensamiento y mejora el rendimiento en los puntos de referencia MultiArith y GSM8K:

<Screenshot src={APECOT} alt="APECOT" />
Fuente de la imagen: [Zhou et al., (2022)](https://arxiv.org/abs/2211.01910)

Este documento toca un tema importante relacionado con la ingeniería de prompts, que es la idea de optimizar automáticamente las solicitudes. Si bien no profundizamos en este tema en esta guía, aquí hay algunos documentos clave si está interesado en el tema:

- [AutoPrompt](https://arxiv.org/abs/2010.15980) - propone un enfoque para crear automáticamente mensajes para un conjunto diverso de tareas basadas en la búsqueda guiada por gradiente.
- [Prefix Tuning](https://arxiv.org/abs/2101.00190) - una alternativa ligera al ajuste fino que antepone un prefijo continuo entrenable para tareas NLG.
- [Prompt Tuning](https://arxiv.org/abs/2104.08691) - propone un mecanismo para aprender indicaciones suaves a través de la propagación hacia atrás.